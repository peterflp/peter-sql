## Case Study Questions - Data Cleaning


In a single query, perform the following operations and generate a new table in the `data_mart` schema named `weekly_sales_cleaned`:

- Convert the `week_date` to a `DATE` format.

- Add a `week_number` as the second column for each `week_date` value, for example any value from the 1st of January to 7th of January will be 1, 8th to 14th will be 2 etc.

- Add a `month_number` with the calendar month for each `week_date value as the 3rd column.

- Add a `calendar_year` column as the 4th column containing either 2018, 2019 or 2020 values.

- Add a new column called `age_band` after the original `segment` column using the following mapping on the number inside the `segment` value.

    segment |	age_band |
    |--|--|
    1 |	Young Adults |
    2 |	Middle Aged |
    3 or 4 |	Retirees |

- Add a new `demographic` column using the following mapping for the first letter in the `segment` values:

    segment |	demographic |
    |--|--|
    C |	Couples |
    F |	Families |

- Ensure all `null` string values with an `"unknown"` string value in the original `segment` column as well as the new `age_band` and `demographic` columns

- Generate a new `avg_transaction` column as the `sales` value divided by `transactions` rounded to 2 decimal places for each record

<br>

---

## Solution:

Let's collaborate on running the queries using PostgreSQL on [Data Cleaning - DB Fiddle](https://www.db-fiddle.com/f/dvuiG4Jdk4eqR3q1V13v7m/2).

---



```sql
DROP TABLE IF EXISTS weekly_sales_cleaned;

CREATE TABLE weekly_sales_cleaned as
SELECT TO_DATE(week_date, 'DD/MM/YYYY') as week_date,
       EXTRACT(WEEK FROM TO_DATE(week_date, 'DD/MM/YYYY')) as week_number,
       EXTRACT(MONTH FROM TO_DATE(week_date, 'DD/MM/YYYY')) as month_number,
       EXTRACT(YEAR FROM TO_DATE(week_date, 'DD/MM/YYYY')) as calendar_year,
       region,
       platform,
       COALESCE(NULLIF(segment, ''), 'unknown') as segment,
       CasE
           WHEN NULLIF(segment, '') SIMILAR TO '[1]' THEN 'Young Adults'
           WHEN NULLIF(segment, '') SIMILAR TO '[2]' THEN 'Middle Aged'
           WHEN NULLIF(segment, '') SIMILAR TO '[3-4]' THEN 'Retirees'
           ELSE 'unknown'
       END as age_band,
       CasE
           WHEN NULLIF(segment, '') SIMILAR TO 'C%' THEN 'Couples'
           WHEN NULLIF(segment, '') SIMILAR TO 'F%' THEN 'Families'
           ELSE 'unknown'
       END as demographic,
       COALESCE(NULLIF(customer_type, ''), 'unknown') as customer_type,
       transactions,
       sales,
       ROUND(sales::NUMERIC / transactions, 2) as avg_transaction
FROM   data_mart.weekly_sales;
```

```sql
SELECT *
FROM   weekly_sales_cleaned
LIMIT 10
```

#### Result set:

week_date |	week_number |	month_number |	calendar_year |	region |	platform |	segment |	age_band |	demographic |	customer_type |	transactions |	sales |	avg_transaction |
--|--|--|--|--|--|--|--|--|--|--|--|--|
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	ASIA |	Retail |	C3 |	unknown |	Couples |	New |	120631 |	3656163 |	30.31 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	ASIA |	Retail |	F1 |	unknown |	Families |	New |	31574 |	996575 |	31.56 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	USA |	Retail |	null |	unknown |	unknown |	Guest |	529151 |	16509610 |	31.20 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	EUROPE |	Retail |	C1 |	unknown |	Couples |	New |	4517 |	141942 |	31.42 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	AFRICA |	Retail |	C2 |	unknown |	Couples |	New |	58046 |	1758388 |	30.29 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	CANADA |	Shopify |	F2 |	unknown |	Families |	Existing |	1336 |	243878 |	182.54 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	AFRICA |	Shopify |	F3 |	unknown |	Families |	Existing |	2514 |	519502 |	206.64 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	ASIA |	Shopify |	F1 |	unknown |	Families |	Existing |	2158 |	371417 |	172.11 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	AFRICA |	Shopify |	F2 |	unknown |	Families |	New |	318 |	49557 |	155.84 |
0031-08-20T00:00:00.000Z |	34 |	8 |	31 |	AFRICA |	Retail |	C3 |	unknown |	Couples |	New |	111032 |	3888162 |	35.02 |



---

